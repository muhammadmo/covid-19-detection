{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadmo/covid-19-detection/blob/main/IOT_framework_(CT_data_%2B_InceptionV3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAgIeuw_Dwko",
        "outputId": "22292fc0-c2ef-43be-8b83-6d70ccee275a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.63.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "iAV-zKKSFYCq",
        "outputId": "b0f94e57-fa3a-41b5-f68c-6270a644c15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5000fccd-b44d-42d1-aefc-2ef403c73016\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5000fccd-b44d-42d1-aefc-2ef403c73016\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"muhammadmoosavi\",\"key\":\"1fa1bc8aae4bfd517b860f44615ff8d9\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "JIxJVS5lFaS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d maedemaftouni/large-covid19-ct-slice-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ZP19mlFfwZ",
        "outputId": "b48d0231-3325-440e-991c-f15d25dfaa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading large-covid19-ct-slice-dataset.zip to /content\n",
            "100% 2.05G/2.06G [00:13<00:00, 141MB/s]\n",
            "100% 2.06G/2.06G [00:13<00:00, 170MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d drsurabhithorat/covid-19-ct-scan-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihO8xVg1FkcX",
        "outputId": "86b2d70e-4504-4311-bfad-2a5c4b8e8222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading covid-19-ct-scan-dataset.zip to /content\n",
            " 99% 1.03G/1.04G [00:06<00:00, 186MB/s]\n",
            "100% 1.04G/1.04G [00:06<00:00, 163MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"large-covid19-ct-slice-dataset.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zipp:\n",
        "  zipp.extractall()\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImhrPTDfFmvq",
        "outputId": "2c842274-2140-4019-f6b8-bd5298052de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"covid-19-ct-scan-dataset.zip\"\n",
        "\n",
        "with ZipFile(file_name,'r') as zipp:\n",
        "  zipp.extractall()\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuky03aIFtsR",
        "outputId": "3820d3b7-fa87-4c18-9bb9-10ebecf9f1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split_folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghrI2Ak-F-Qn",
        "outputId": "1ff1ad40-777b-40ba-cc23-5ed2bd491ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split_folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "input_folder = \"/content/dataset\"\n",
        "output = \"/content/splited_dataset\"\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output, seed=42, ratio=(.7, .1, .2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dhp5IqkAGAXo",
        "outputId": "c01ac0a8-e533-4f58-b32b-e2b85164fc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 10239 files [00:07, 1355.06 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "train_path = '/content/splited_dataset/train'\n",
        "test_path = '/content/splited_dataset/test'\n",
        "valid_path = '/content/splited_dataset/val'\n",
        "\n",
        "#set defult image size\n",
        "batch_size = 16\n",
        "img_width = 229\n",
        "img_height = 229"
      ],
      "metadata": {
        "id": "GTUGg-tJGFGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# Create Image Data Generator for Train Set\n",
        "image_gen = ImageDataGenerator(\n",
        "                                rotation_range=15,\n",
        "                                width_shift_range=0.05,\n",
        "                                height_shift_range=0.05,\n",
        "                                rescale = 1./255,\n",
        "                                shear_range = 0.2,\n",
        "                                zoom_range = 0.2,\n",
        "                                horizontal_flip = True,\n",
        "                               )\n",
        "# Create Image Data Generator for Test/Validation Set\n",
        "test_data_gen = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "eICpvr_IGKPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = image_gen.flow_from_directory(\n",
        "      train_path,\n",
        "      target_size=(img_height, img_width),\n",
        "      color_mode='rgb',\n",
        "      class_mode='sparse',\n",
        "      batch_size=batch_size\n",
        "      )\n",
        "test = test_data_gen.flow_from_directory(\n",
        "      test_path,\n",
        "      target_size=(img_height, img_width),\n",
        "      color_mode='rgb',\n",
        "      shuffle=False,\n",
        "#setting shuffle as False just so we can later compare it with predicted values without having indexing problem\n",
        "      class_mode='sparse',\n",
        "      batch_size=batch_size\n",
        "      )\n",
        "valid = test_data_gen.flow_from_directory(\n",
        "      valid_path,\n",
        "      target_size=(img_height, img_width),\n",
        "      color_mode='rgb',\n",
        "      class_mode='sparse',\n",
        "      batch_size=batch_size\n",
        "      )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7_cDFGLGM5J",
        "outputId": "7c595d4f-4836-48b4-813f-5b8f1621d222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7165 images belonging to 3 classes.\n",
            "Found 2051 images belonging to 3 classes.\n",
            "Found 1022 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(229, 229, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qt5rIpWGQgL",
        "outputId": "a3179ce2-1179-43de-e68f-8d02efd3249d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHj4mo1MGTh3",
        "outputId": "15e64e13-627a-4876-f9de-78e3d2956c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 229, 229, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 114, 114, 32  864         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 114, 114, 32  96         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 114, 114, 32  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 112, 112, 32  9216        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 112, 112, 32  96         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 112, 112, 64  18432       ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 112, 112, 64  192        ['conv2d_2[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 112, 112, 64  0           ['batch_normalization_2[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 55, 55, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 55, 55, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 55, 55, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 55, 55, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 53, 53, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 53, 53, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 53, 53, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 26, 26, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 26, 26, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 26, 26, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 26, 26, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 26, 26, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 26, 26, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 26, 26, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 26, 26, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 26, 26, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 26, 26, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 26, 26, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 26, 26, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 26, 26, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 26, 26, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 26, 26, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 26, 26, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 26, 26, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 26, 26, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 26, 26, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 26, 26, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 26, 26, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 26, 26, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 26, 26, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 26, 26, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 26, 26, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 26, 26, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 26, 26, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 26, 26, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 26, 26, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 26, 26, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 26, 26, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 26, 26, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 26, 26, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 26, 26, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 26, 26, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 26, 26, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 26, 26, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 26, 26, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 26, 26, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 26, 26, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 26, 26, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 26, 26, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 26, 26, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 26, 26, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 26, 26, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 26, 26, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 26, 26, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 26, 26, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 26, 26, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 26, 26, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 26, 26, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 26, 26, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 26, 26, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 26, 26, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 26, 26, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 26, 26, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 26, 26, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 26, 26, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 26, 26, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 26, 26, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 26, 26, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 26, 26, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 26, 26, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 26, 26, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 26, 26, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 26, 26, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 26, 26, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 12, 12, 384)  995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 12, 12, 96)   82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 12, 12, 384)  1152       ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 12, 12, 96)  288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 12, 12, 384)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 12, 12, 96)   0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0          ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 12, 12, 768)  0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 12, 12, 128)  384        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 12, 12, 128)  384        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 12, 12, 128)  98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 12, 12, 128)  384        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 12, 12, 128)  384        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 12, 12, 128)  114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 12, 12, 128)  384        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 12, 12, 128)  384        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 12, 12, 768)  0          ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 12, 12, 192)  172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 12, 12, 192)  576        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 12, 12, 192)  576        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 12, 12, 192)  576        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 12, 12, 192)  576        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 12, 12, 768)  0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 12, 12, 160)  480        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 12, 12, 160)  480        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 12, 12, 160)  480        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 12, 12, 160)  480        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 12, 12, 160)  480        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 12, 12, 160)  480        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 12, 12, 768)  0          ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 12, 12, 192)  576        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 12, 12, 192)  576        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 12, 12, 192)  576        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 12, 12, 192)  576        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 12, 12, 768)  0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 12, 12, 160)  480        ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 12, 12, 160)  480        ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 12, 12, 160)  122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 12, 12, 160)  480        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 12, 12, 160)  480        ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 12, 12, 160)  179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 12, 12, 160)  480        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 12, 12, 160)  480        ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 12, 12, 160)  0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 12, 12, 768)  0          ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 12, 12, 192)  215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 12, 12, 192)  576        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 12, 12, 192)  576        ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 12, 12, 192)  576        ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 12, 12, 192)  576        ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 12, 12, 768)  0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 12, 12, 192)  576        ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 12, 12, 192)  576        ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 12, 12, 192)  576        ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 12, 12, 192)  576        ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 12, 12, 192)  576        ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 12, 12, 192)  576        ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 12, 12, 768)  0          ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 12, 12, 192)  147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 12, 12, 192)  576        ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 12, 12, 192)  576        ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 12, 12, 192)  576        ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 12, 12, 192)  576        ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 12, 12, 768)  0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 12, 12, 192)  576        ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 12, 12, 192)  576        ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 12, 12, 192)  147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 12, 12, 192)  258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 12, 12, 192)  576        ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 12, 12, 192)  576        ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 12, 12, 192)  0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 5, 5, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 5, 5, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 5, 5, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 5, 5, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 5, 5, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 5, 5, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 5, 5, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 5, 5, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 5, 5, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 5, 5, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 5, 5, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 5, 5, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 5, 5, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 5, 5, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 5, 5, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 5, 5, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 5, 5, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 5, 5, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 5, 5, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 5, 5, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 5, 5, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 5, 5, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 5, 5, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 5, 5, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 5, 5, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 5, 5, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 5, 5, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 5, 5, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 5, 5, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 5, 5, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 5, 5, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 5, 5, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 5, 5, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 21,768,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "optimizer = keras.optimizers.Adam(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(Conv2D(3, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(img_width, img_height, 1)))\n",
        "\n",
        "model.add(conv_base)\n",
        "\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "#model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(0.3))\n",
        "#model.add(layers.BatchNormalization())\n",
        "\n",
        "#model.add(layers.Dense(4096, activation='relu'))\n",
        "#model.add(Dense(activation = 'relu', units = 64))\n",
        "model.add(Dense(3,activation=\"softmax\"))\n",
        "model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "#model.compile(optimizer = RMSprop(lr=1e-2) , loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "conv_base.trainable = False\n",
        "#fine-tuning\n",
        "'''\n",
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name == 'block5_conv1':\n",
        "    set_trainable = True\n",
        "  if set_trainable:\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "'''\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZBVayueGWJA",
        "outputId": "0cc8e231-e7ee-445c-ce48-42e7b079e310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_94 (Conv2D)          (None, 229, 229, 3)       30        \n",
            "                                                                 \n",
            " inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 3075      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,953,665\n",
            "Trainable params: 3,150,881\n",
            "Non-trainable params: 21,802,784\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "#early stopping\n",
        "early = EarlyStopping(monitor=\"val_loss\",\n",
        "                      mode=\"auto\",\n",
        "                      patience=9)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience = 4, verbose=1,factor=1e-1, min_lr=0.000001)\n",
        "\n",
        "checkpoint_filepath = 'checkpointCNN.h5'\n",
        "Model_check = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "callbacks_list = [ early, learning_rate_reduction]"
      ],
      "metadata": {
        "id": "sWLTHBB_GdAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train,\n",
        "                    batch_size=16,\n",
        "                    epochs=30,\n",
        "                    validation_data=valid,\n",
        "                    callbacks=[early,learning_rate_reduction, Model_check])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-DdccLBGe9h",
        "outputId": "e800bf1d-8971-4254-c119-90f1ed29c786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8207\n",
            "Epoch 1: val_loss improved from inf to 0.30196, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 225s 447ms/step - loss: 0.4119 - accuracy: 0.8207 - val_loss: 0.3020 - val_accuracy: 0.8806 - lr: 0.0030\n",
            "Epoch 2/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9364\n",
            "Epoch 2: val_loss improved from 0.30196 to 0.28515, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 181s 405ms/step - loss: 0.1693 - accuracy: 0.9364 - val_loss: 0.2851 - val_accuracy: 0.8689 - lr: 0.0030\n",
            "Epoch 3/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.9538\n",
            "Epoch 3: val_loss improved from 0.28515 to 0.23676, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 181s 404ms/step - loss: 0.1234 - accuracy: 0.9538 - val_loss: 0.2368 - val_accuracy: 0.9295 - lr: 0.0030\n",
            "Epoch 4/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.9597\n",
            "Epoch 4: val_loss improved from 0.23676 to 0.11963, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 176s 392ms/step - loss: 0.1100 - accuracy: 0.9597 - val_loss: 0.1196 - val_accuracy: 0.9658 - lr: 0.0030\n",
            "Epoch 5/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.9699\n",
            "Epoch 5: val_loss improved from 0.11963 to 0.04059, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 182s 405ms/step - loss: 0.0879 - accuracy: 0.9699 - val_loss: 0.0406 - val_accuracy: 0.9892 - lr: 0.0030\n",
            "Epoch 6/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0696 - accuracy: 0.9742\n",
            "Epoch 6: val_loss did not improve from 0.04059\n",
            "448/448 [==============================] - 173s 385ms/step - loss: 0.0696 - accuracy: 0.9742 - val_loss: 0.1301 - val_accuracy: 0.9374 - lr: 0.0030\n",
            "Epoch 7/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9779\n",
            "Epoch 7: val_loss did not improve from 0.04059\n",
            "448/448 [==============================] - 182s 405ms/step - loss: 0.0614 - accuracy: 0.9779 - val_loss: 0.0853 - val_accuracy: 0.9638 - lr: 0.0030\n",
            "Epoch 8/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9841\n",
            "Epoch 8: val_loss did not improve from 0.04059\n",
            "448/448 [==============================] - 182s 406ms/step - loss: 0.0469 - accuracy: 0.9841 - val_loss: 0.1194 - val_accuracy: 0.9658 - lr: 0.0030\n",
            "Epoch 9/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9846\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.00030000000260770325.\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.04059\n",
            "448/448 [==============================] - 184s 411ms/step - loss: 0.0423 - accuracy: 0.9846 - val_loss: 0.0938 - val_accuracy: 0.9648 - lr: 0.0030\n",
            "Epoch 10/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9886\n",
            "Epoch 10: val_loss improved from 0.04059 to 0.03397, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 180s 402ms/step - loss: 0.0292 - accuracy: 0.9886 - val_loss: 0.0340 - val_accuracy: 0.9883 - lr: 3.0000e-04\n",
            "Epoch 11/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9905\n",
            "Epoch 11: val_loss improved from 0.03397 to 0.02879, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 179s 398ms/step - loss: 0.0247 - accuracy: 0.9905 - val_loss: 0.0288 - val_accuracy: 0.9892 - lr: 3.0000e-04\n",
            "Epoch 12/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9939\n",
            "Epoch 12: val_loss improved from 0.02879 to 0.02634, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 176s 393ms/step - loss: 0.0198 - accuracy: 0.9939 - val_loss: 0.0263 - val_accuracy: 0.9912 - lr: 3.0000e-04\n",
            "Epoch 13/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9941\n",
            "Epoch 13: val_loss improved from 0.02634 to 0.02592, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 176s 392ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0259 - val_accuracy: 0.9922 - lr: 3.0000e-04\n",
            "Epoch 14/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9943\n",
            "Epoch 14: val_loss did not improve from 0.02592\n",
            "448/448 [==============================] - 172s 385ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 0.0270 - val_accuracy: 0.9912 - lr: 3.0000e-04\n",
            "Epoch 15/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9960\n",
            "Epoch 15: val_loss did not improve from 0.02592\n",
            "448/448 [==============================] - 173s 386ms/step - loss: 0.0138 - accuracy: 0.9960 - val_loss: 0.0285 - val_accuracy: 0.9902 - lr: 3.0000e-04\n",
            "Epoch 16/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9954\n",
            "Epoch 16: val_loss improved from 0.02592 to 0.02352, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 175s 391ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0235 - val_accuracy: 0.9941 - lr: 3.0000e-04\n",
            "Epoch 17/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9967\n",
            "Epoch 17: val_loss improved from 0.02352 to 0.02103, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 177s 394ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0210 - val_accuracy: 0.9941 - lr: 3.0000e-04\n",
            "Epoch 18/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9965\n",
            "Epoch 18: val_loss improved from 0.02103 to 0.01986, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 177s 395ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0199 - val_accuracy: 0.9912 - lr: 3.0000e-04\n",
            "Epoch 19/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 0.9946\n",
            "Epoch 19: val_loss improved from 0.01986 to 0.01838, saving model to checkpointCNN.h5\n",
            "448/448 [==============================] - 178s 396ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.0184 - val_accuracy: 0.9932 - lr: 3.0000e-04\n",
            "Epoch 20/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9967\n",
            "Epoch 20: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 176s 393ms/step - loss: 0.0094 - accuracy: 0.9967 - val_loss: 0.0203 - val_accuracy: 0.9922 - lr: 3.0000e-04\n",
            "Epoch 21/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9968\n",
            "Epoch 21: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 175s 390ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.0266 - val_accuracy: 0.9912 - lr: 3.0000e-04\n",
            "Epoch 22/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9973\n",
            "Epoch 22: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 173s 385ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0237 - val_accuracy: 0.9941 - lr: 3.0000e-04\n",
            "Epoch 23/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 172s 384ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0275 - val_accuracy: 0.9912 - lr: 3.0000e-04\n",
            "Epoch 24/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9962\n",
            "Epoch 24: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 171s 381ms/step - loss: 0.0085 - accuracy: 0.9962 - val_loss: 0.0241 - val_accuracy: 0.9912 - lr: 3.0000e-05\n",
            "Epoch 25/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9971\n",
            "Epoch 25: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 174s 387ms/step - loss: 0.0075 - accuracy: 0.9971 - val_loss: 0.0224 - val_accuracy: 0.9922 - lr: 3.0000e-05\n",
            "Epoch 26/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9968\n",
            "Epoch 26: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 176s 393ms/step - loss: 0.0089 - accuracy: 0.9968 - val_loss: 0.0243 - val_accuracy: 0.9922 - lr: 3.0000e-05\n",
            "Epoch 27/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 175s 390ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0234 - val_accuracy: 0.9912 - lr: 3.0000e-05\n",
            "Epoch 28/30\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9973\n",
            "Epoch 28: val_loss did not improve from 0.01838\n",
            "448/448 [==============================] - 177s 395ms/step - loss: 0.0073 - accuracy: 0.9973 - val_loss: 0.0236 - val_accuracy: 0.9922 - lr: 3.0000e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(model.history.history).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "q49JOChOGhP5",
        "outputId": "dd79ea9b-4773-4a90-eefb-8b608146f81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2446773c90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('checkpointCNN.h5')\n",
        "test_accu = model.evaluate(test)\n",
        "print('The testing accuracy is :',test_accu[1]*100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IErASiyxGwk6",
        "outputId": "0b6a04d4-665f-4c73-a067-ef4755affbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 17s 120ms/step - loss: 0.0391 - accuracy: 0.9937\n",
            "The testing accuracy is : 99.3661642074585 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "rounded_labels=np.argmax(preds, axis=1)\n",
        "rounded_labels[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ynoj7oLGyhQ",
        "outputId": "0e4528e5-dd9b-411f-f609-5615abd3c61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cmm = confusion_matrix(rounded_labels, test.classes)\n",
        "cmm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho8IljlDGz9h",
        "outputId": "0a2c0b18-003f-47f4-8561-a47238fc7ee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1037,   13,    0],\n",
              "       [   4,  472,    0],\n",
              "       [   0,    0,  525]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "cm = pd.DataFrame(data=confusion_matrix(test.classes, rounded_labels, labels=[0, 1, 2]),index=[\"Actual COVID-19\", \"Actual Normal\", \"Actual CAP\"],\n",
        "columns=[\"Predicted COVID-19\", \"Predicted Normal\", \"Predicted CAP\"])\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "TY4xulXuG1yo",
        "outputId": "81f721f0-bfdd-4d29-f2c1-b5dd8765f7e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f24456134d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa8AAAFRCAYAAADD8yJoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwU1bn/8c93APcNxCBbgooGtwiKhIjmims0IWBiMCRGkmgwiXHJotcY78+oMVcTl6sxG2quaNyjXo37hiImLqhEBVERVFZXVDQqMPP8/qgabMehu2fomerq/r591aurTlVXPd2M88w5deocRQRmZmZ50pB1AGZmZm3l5GVmZrnj5GVmZrnj5GVmZrnj5GVmZrnj5GVmZrnTNesADJa/NsfPK3SwtfvslnUIZhWxYtkCre452vI7p1vPzVf7eh3BycvMrN40NWYdwWpz8jIzqzfRlHUEq83Jy8ys3jTlP3m5w4aZWZ2JaCp7KUXSXyS9IumpgrIeku6U9Fz62j0tl6TzJM2W9ISkHQveMz49/jlJ40td18nLzKzeNK4ofyntYuALLcqOB+6OiC2Bu9NtgP2ALdNlAvBHSJIdcBLwWWAYcFJzwlsVJy8zs3rT1Fj+UkJETAHeaFE8GpiUrk8CxhSUXxKJB4GNJPUG9gXujIg3ImIJcCcfT4gf4XteZmb1puM7bPSKiEXp+mKgV7reF5hXcNz8tGxV5avkmpeZWb1paip7kTRB0rSCZUJbLhXJvFsVf5bVNS8zszpTTkeMD4+NicDENl7iZUm9I2JR2iz4Slq+AOhfcFy/tGwBsHuL8nuLXcA1LzOzetOGmlc73Qg09xgcD9xQUH5I2utwOPBW2rx4O7CPpO5pR4190rJVcs3LzKzeNC6v2KkkXUFSa+opaT5Jr8HTgaslHQq8CIxND78F2B+YDfwb+A5ARLwh6VTgkfS4UyKiZSeQj143aY60LHlsw47nsQ2tVlRibMMPnp5c9u+cNbce6bENzcysCtTACBtOXmZm9cZjG5qZWe645mVmZnkTTZXrsJEVJy8zs3rjmpeZmeWO73mZmVnueCZlMzPLHde8zMwsd3zPy8zMcqe8SSarmpOXmVm9cc3LzMzyJsIdNszMLG9c8zIzs9xxb0MzM8sd17zMzCx33NvQzMxyx82GZmaWOzXQbNhQzkGSxkgKSYPKOPYYSeu0NyBJ35Z0/ir27SdpmqSZkh6XdFbBvgmSZqXLw5J2Tcv/V9LhrXyeW9P1d9LXAZLeS8/7dHqObxeJ80eSZqffS8+C8u6Srpf0RHqO7dr7XXSmE399Np//4tcZc/D3V5a99fZSDjv6BPY/6FAOO/oE3np7KQD33P9PDjjkB3x1/BGM/e5RPPavpwB4+NF/8dXxR6xcdhz5Ze6e8o9MPk/eNTQ08MjDt3PD9ZOyDqVm7bvP7sx4agqzZk7luGOPyDqcztXUVP5SpcpKXsA4YGr6WsoxQLuT16qkSeB84OCI2AYYCsxO930JOBzYNSIGAd8HLpe0KXAF8PUWp/t6Wt7S8xExJCK2To85RtJ3VhHSA8BewIstyk8ApkfEZ4BDgHPb9kmzMWb/vfnT2b/6SNmFl17N8KGDueWqixg+dDAX/fVqAIbvNJjrJv2Bayf9nlNP+DEnnZ58xGE77cC1k37PtZN+z19+dzprrbkmuwzbsdM/Sy046sjDmDXruazDqFkNDQ2cd+5pfGnUwWy/w0gOOmgMW2+9ZdZhdZ5oKn+pUiWTl6T1gF2BQylIApK6SDpT0lNpLeNISUcBfYDJkianx71T8J4DJV2cro+S9FBa07lLUq8SoRwHnBYRswAiojEi/pju+0/g2Ih4Ld33GDAJOAK4GxgkqXd63XVJks7/FbtYRMwBfgIctYr9j0fEC63s2ga4Jz1mFjCgjM+WuaGDt2fDDdb/SNnk+//J6P32AmD0fntxz5R/ArDOOmsjCYD33n8f0vVCd0y+n92GD2Xttdbq4MhrT9++vdl/vz35y19a+/vKKmHYzkN4/vkXmDv3JZYvX87VV9/Al0ftm3VYnadxRflLlSqn5jUauC0ingVel7RTWj4BGAAMTmsZl0XEecBCYGREjCxx3qnA8IgYAlxJkpyK2Q54dBX7tm1l3zRg20geJb8WGJuWjwLujYi3S1wP4DGgZFNpC/8CvgIgaRjwKaBfG89RFV5f8iab9OwBQM+Nu/P6kjdX7rvrvgcYNe57/PBn/49TT/jxx957611T2G/v3Tsr1Jpy9lknc/zPf0VTFTfZ5F2fvpsyb/7CldvzFyyiT59NM4yok9VJs+E4kuRC+trcdLgX8OeIWAEQEW+08dr9gNslPQkcS5KAOkph0+Gqmgxb8/EqRWmnAxtJmg4cCTwO5H4sFkkra1sAe/3HCP5+xQWcd/r/4/wLLvnIsa++9gbPzZnLiM/u1PI0VsIX99+LV155jccefzLrUKyW1XqzoaQewB7AhZJeIEkyY6VW2olWLQrWC9uQfgecHxHbk9yvKtW+NANY1W/Dma3s2yl9D8A/gN6SdgB2AW4uI26AIcDTAJJulzRd0oXF3hARb0fEdyJiMMk9r02AOS2PSzuYTJM07cJLqrN5aOPuG/Hqa8nfJK++9gY9NtrwY8cMHbw98xcuZsmbb60su+2eKez5+V3o1tWdWdtql12GMupL+zD72Qe57K9/YOTIEUy6+Lysw6o5Cxcspn+/Piu3+/XtzcKFizOMqJPVQc3rQODSiPhURAyIiP7AXGA34E7gcEldYWWiA1gKFN48eVnS1pIagAMKyjcEFqTr48uI9bfACZK2Sq/XIKm5a9xvgDMkbZzuGwx8G/gDQEQEcBXJfbBbI+L9UheTNAA4kyTJEhH7RsTgiDisxPs2krRGunkYMKW1JsqImBgRQyNi6GGHlNMPpvPtvutwbrj1LgBuuPUuRu72OQBemr+Q5CuFmc/MZtmy5Wy04QYr33frnfey/167d3q8teAXJ57OgM2HMnCr4Xzz4B8yefIDjP92q7ddbTU8Mm06AwduxoAB/enWrRtjx47m7zfdkXVYnacGklepP43HAWe0KLs2LT8S2Ap4QtJy4AKS3oATgdskLUzvex0P3AS8SnIfar30PL8ErpG0hKSDw2bFAomIJyQdA1yRdsWP9LxExI2S+gL/kBQkCfTgiFhUcIorSO6rHV/kMltIepykFrgUOC8iLm7twLRzynHApul3cEua2LYGJqVxzCDp6FL1jj3pdB55/AnefPNt9hxzMD889Fsc9q2x/PS/fs11N91On00/wVmnngDAnfdO5cZb76Zr166steYanHnK8SubFBcsepnFr7zG0CHbZ/lxzIpqbGzk6GNO5JabL6dLQwMXT7qKmTOfzTqszhNR+pgqp6iBD5F3y1+b43+EDrZ2n92yDsGsIlYsW9Cee/Ef8d5l/1X275y1v3nqal+vI/imhJlZvanijhjlcvIyM6s3VXwvq1xOXmZm9aYGbhc5eZmZ1RvXvMzMLHecvMzMLG+iMfeD/pQ9qryZmdWKCj6kLOnHkmakg7RfIWktSZulA6/PlnRV88ANktZMt2en+we09yM4eZmZ1ZsKjW2YDg5xFDA0IrYDupCMH3sGcE5EDASW8OFgDYcCS9Lyc/j4IBhlc/IyM6s3TVH+UlpXYO10qMB1gEUkY+L+Ld0/CRiTro9Ot0n379nGsXJXcvIyM6s3FWo2jIgFJGPAvkSStN4imZ7qzeYZR4D5QN90vS8wL33vivT4jdvzEZy8zMzqTWNj2UvhDBjpMqH5NJK6k9SmNiOZiHhd4Aud8RHc29DMrN60oat8REwkGXC9NXsBcyPiVQBJ1wEjSOY07JrWrvrx4QwiC4D+wPy0mXFD4PX2fATXvMzM6k3l7nm9BAyXtE5672pPkvkVJ5NMqQXJlFc3pOs38uEUWAcC90Q7R4d3zcvMrN5UaGDeiHhI0t+Ax4AVJDPHTySZ8PdKSb9Kyy5K33IRcKmk2cAbfDjDfZs5eZmZ1ZvyehGWJSJOAk5qUTwHGNbKse8DX6vEdZ28zMzqTHh4KDMzy50aGB7KycvMrN5UsNkwK05eZmb1xs2GZmaWO655mZlZ7lSoq3yWnLzMzOqNa15mZpY3scK9Dc3MLG9c8zIzs9zxPS8zM8sd17zMzCxvwsnLzMxyxx02zMwsd1zzMjOz3HHyMjOzvGnn5MVVxcnLzKzeuOZllbBev//IOoSad0v33bIOoebtv+T+rEOwcjl5mZlZ3sQKP6RsZmZ5k//c5eRlZlZv/JCymZnlj5OXmZnljpsNzcwsb9xsaGZmuRMrnLzMzCxv3GxoZmZ5UwNzUTp5mZnVHScvMzPLG9e8zMwsd2JF1hGsPicvM7M645qXmZnljpOXmZnlTyjrCFZbQ9YBmJlZ54qm8pdSJG0k6W+SZkl6WtLnJPWQdKek59LX7umxknSepNmSnpC0Y3s/g5OXmVmdiSaVvZThXOC2iBgE7AA8DRwP3B0RWwJ3p9sA+wFbpssE4I/t/QxOXmZmdaapUWUvxUjaEPg8cBFARCyLiDeB0cCk9LBJwJh0fTRwSSQeBDaS1Ls9n8HJy8yszrSl2VDSBEnTCpYJBafaDHgV+F9Jj0u6UNK6QK+IWJQesxjola73BeYVvH9+WtZm7rBhZlZnymwOTI6NmAhMXMXursCOwJER8ZCkc/mwibD5/SGp4iMBu+ZlZlZnIspfSpgPzI+Ih9Ltv5Eks5ebmwPT11fS/QuA/gXv75eWtZmTl5lZnalUh42IWAzMk/TptGhPYCZwIzA+LRsP3JCu3wgckvY6HA68VdC82CZuNjQzqzOlOmK00ZHAZZLWAOYA3yGpGF0t6VDgRWBseuwtwP7AbODf6bHt4uRlZlZn2nLPq+S5IqYDQ1vZtWcrxwZwRCWu6+RlZlZnogZG2HDyMjOrMx7b0MzMcqfJNS8zM8sbNxuamVnuVLi3YSacvMzM6kwlextmxcnLzKzO1MI9rw4ZYUPSGEkhaVAZxx4jaZ3VuNa3JZ2/ivImSZ8pKHtK0oD2XqsdsQ2Q9FRnXa+j/PnPZzLvpcd57NG7VpaddNLPmPbIHTz80G3cfNNl9O7dq8gZbJUaxPC7/pshfz0OgJ1v+CXD7z6d4Xefzuf/9QcGX/xTADb96gg+N/kMPnfvbxh20ymst80ns4y6Juy7z+7MeGoKs2ZO5bhjK/LoUW5EqOylWnXU8FDjgKnpaynHAO1OXiXMB37R3jdL6lLBWHLr0kuvYdSXv/WRsrPP/hNDd96HYZ/9Arfcche/OOHojKLLt099bz/efW7hyu1HRv+SB/c8ngf3PJ63pj3Hyzc/DMB7L77KI2NO4Z+7H8ecs69j27MmrOqUVoaGhgbOO/c0vjTqYLbfYSQHHTSGrbfeMuuwOk0FxzbMTMWTl6T1gF2BQ4GvF5R3kXRmWvt5QtKRko4C+gCTJU1Oj3un4D0HSro4XR8l6aF02P27JJXzp/5NwLYF424VxjlO0pNpPGcUlL8j6SxJ/wI+l27/VtKM9LrDJN0raY6kL6fvGSDpfkmPpcsu7fjqqtbUqQ+xZMmbHylbunTlPxPrrLtOVf+QV6s1e/eg5947suCyez62r8t6a9Nj12155dZpALw17VlWvPUuAG8++hxr9u7RqbHWmmE7D+H5519g7tyXWL58OVdffQNfHrVv1mF1mqZQ2Uu16oia12iSWTWfBV6XtFNaPgEYAAyOiM8Al0XEecBCYGREjCxx3qnA8IgYAlwJHFdGLE3Ab4ATCgsl9QHOAPYABgM7S2qeLG1d4KGI2CEipqbb90TEtsBS4FfA3sABwCnpe14B9o6IHYGDgPPKiC33Tj75OGbPfohxXz+Ak085M+twcmfQqeN59pTLiKaPZ/5P7DeUN+6fQeM7731sX99vjOS1e6Z3Rog1q0/fTZk3/8Ma7/wFi+jTZ9MMI+pcTU0qe6lWHZG8xpEkF9LX5qbDvYA/R8QKgIh4o43n7QfcLulJ4Fhg2zLfdzkwXNJmBWU7A/dGxKtpPJeRzAYK0AhcW3DsMuC2dP1J4L6IWJ6uD0jLuwEXpLFdA2zTlg+WVyed9BsGDvwsV1x5PT/4wbezDidXeu69I8tee4ulT8xtdX/vA0aw6PoHPlbefcQ29P3GSJ479fKODtFqmGteLUjqQVKbuVDSCyRJZqyktnwDhX+GrlWw/jvg/IjYHji8xb5VnyxJTmcB/1nm9d+PiMaC7eXpYJKQ1OQ+SM/bxIe9NX8MvAzsQDJA5RqlLlI4O2lj4zulDq9qV155PQeM2T/rMHJlo2Fbscm+O7HbI7/jM38+ih4jtmW73yedBrr1WJ8NhmzBa3c9/pH3rLfNJ9n27MOZPv5Mli/J989M1hYuWEz/fn1Wbvfr25uFCxdnGFHncoeNjzsQuDQiPhURAyKiPzAX2A24EzhcUldYmeggaYpbv+AcL0vaWlIDSdNcsw35cNKy8bTNxSQ1v03S7YeB/5DUM+2UMQ64r43nLLQhsChNaN8CSnb0iIiJETE0IoZ26bLealw6GwO3GLByfdSX9uGZZ2ZnF0wOzT7tSqYMOYL7dz6SJw4/jzcemMFTR/wegF5f+iyv3fkYTR8sX3n8Wn03ZvBffsKTR/yef89p1/RHVuCRadMZOHAzBgzoT7du3Rg7djR/v+mOrMPqNLVQ86r0c17jSO4lFbo2LT8S2Ap4QtJy4ALgfJLppW+TtDC973U8SUeLV4FpQPNv9l8C10haAtwDFDYDFhURyySdB5ybbi+SdDwwGRBwc0TcUOwcJfwBuFbSISRNjO+uxrmqziWXnM/ndxtOz549eH72w5z6q7P4wr57sNVWW9DU1MRLL83nR0eeUPpEVpZNx+zC3N999Mdx859+lW7d12PrM74LQKxo5KF9292Rtu41NjZy9DEncsvNl9OloYGLJ13FzJnPZh1Wp6mF/lUKdxPL3Jpr9fc/Qgf7+4Yjsg6h5u2/5P6sQ6gLK5YtWO3q0AObHlj275wRi/9WldUvj7BhZlZnamBGFCcvM7N6E1RlZapNnLzMzOpMK48W5o6Tl5lZnWlyzcvMzPLGzYZmZpY7jU5eZmaWN+5taGZmuePkZWZmueN7XmZmljtVPNNJ2Zy8zMzqjLvKm5lZ7jSWPqTqOXmZmdWZpjZNsVidnLzMzOpMDYwO5eRlZlZv3FXezMxyx70Nzcwsd2pheKiGrAMwM7PO1aTyl3JI6iLpcUk3pdubSXpI0mxJV0laIy1fM92ene4f0N7P4ORlZlZnmtqwlOlo4OmC7TOAcyJiILAEODQtPxRYkpafkx7XLk5eZmZ1JtqwlCKpH/BF4MJ0W8AewN/SQyYBY9L10ek26f490+PbzMnLzKzOtKXZUNIESdMKlgktTvc/wHF8WFHbGHgzIlak2/OBvul6X2AeQLr/rfT4NnOHDTOzOtOWrvIRMRGY2No+SV8CXomIRyXtXonYyuXkZWZWZxor19lwBPBlSfsDawEbAOcCG0nqmtau+gEL0uMXAP2B+ZK6AhsCr7fnwm42NDOrM5XqsBERP4+IfhExAPg6cE9EfBOYDByYHjYeuCFdvzHdJt1/T0S0a8APJy8zszrTAb0NW/pP4CeSZpPc07ooLb8I2Dgt/wlwfHsv4GZDM7M60xFjG0bEvcC96focYFgrx7wPfK0S13PyMjOrMx4eyszMcscD85qZWe54MkozM8sdNxuamVnuuNnQKqKxqRZ+lKrb/kvuzzqEmvdwr6FZh2Bl8kzKZmaWO001kL6cvMzM6ow7bJiZWe7Uwo0KJy8zszrj3oZmZpY7vudlZma5k//U5eRlZlZ3fM/LzMxyp7EG6l5OXmZmdcY1LzMzyx132DAzs9zJf+py8jIzqztuNjQzs9xxhw0zM8sd3/MyM7PcyX/qcvIyM6s7rnmZmVnuuMOGmZnlTrjmZWZmeePehmZmljtuNjQzs9xpCte8zMwsZ/Kfupy8zMzqjrvKm5lZ7ri3oZmZ5c4KJy8zM8sb17zMzCx3aqGrfEPWAZiZWeeKiLKXYiT1lzRZ0kxJMyQdnZb3kHSnpOfS1+5puSSdJ2m2pCck7djez+DkZWZWZ5qIspcSVgA/jYhtgOHAEZK2AY4H7o6ILYG7022A/YAt02UC8Mf2fgYnLzOzOtNIlL0UExGLIuKxdH0p8DTQFxgNTEoPmwSMSddHA5dE4kFgI0m92/MZnLzMzOpMW2pekiZImlawTGjtnJIGAEOAh4BeEbEo3bUY6JWu9wXmFbxtflrWZlWbvCSNkRSSBpVx7DGS1lmNa31b0vmr2Ldf+g82U9Ljks5qsX+6pCtblF0saW667zFJn2tvbNVm3312Z8ZTU5g1cyrHHXtE1uHULH/PlbPtPyay9Z3nMui2c/j0zcn/vn1/8W22mfx7tr7jXDa/4Od02WBdANbo9wkGP3c1g247h0G3nUP/X/8gy9A7TFvueUXExIgYWrBMbHk+SesB1wLHRMTbLa4VdMCgHtXc23AcMDV9PanEsccAfwX+XckAJG0HnA98MSJmSepC0k7bvH9roAuwm6R1I+LdgrcfGxF/k7QP8GfgM5WMLQsNDQ2cd+5pfGH/ccyfv4gH/3kLf7/pDp5++rmsQ6sp/p4r79mxJ9K4ZOnK7bfvn86C0y+Bxib6/PwQeh3xVRb+9yUAfPDiYmZ94cdZhdopKtnbUFI3ksR1WURclxa/LKl3RCxKmwVfScsXAP0L3t4vLWuzqqx5pVl8V+BQ4OsF5V0knSnpqbSnypGSjgL6AJMlTU6Pe6fgPQdKujhdHyXpobQGdZekXhR3HHBaRMwCiIjGiCi8wTgOuBS4g6QttzVTgIHlf/rqNWznITz//AvMnfsSy5cv5+qrb+DLo/bNOqya4++54y2dMh0ak1/h7z7+LGv07plxRJ0r2vBfMZIEXAQ8HRFnF+y6ERifro8HbigoPyTtdTgceKugebFNqjJ5kSSC2yLiWeB1STul5ROAAcDgiPgMSaY/D1gIjIyIkSXOOxUYHhFDgCtJklMx2wGPFtl/UHqeK0gSWWtGAU+WuE4u9Om7KfPmL1y5PX/BIvr02TTDiGqTv+cKC9jyspMZdPNZbPyNfT62u+fYPXl78of/m6/RvxeDbj2HLa85jXWHbdOZkXaaCvY2HAF8C9gjvU0yXdL+wOnA3pKeA/ZKtwFuAeYAs4ELgB+29zNUa7PhOODcdP3KdPtRki/hTxGxAiAi3mjjefsBV6XV2DWAue0NUNJQ4LWIeEnSAuAvknoUxPRbSScCr5LUIM0sA89+9XiWL36DrhtvyMDLT+aD5+fzzkMzAdj0yK8RjU28cf19ACx/5Q2e+uxhNL65lLW334ItLjyBmXv+iKZ33svyI1RcY1Sm4TAipgJaxe49Wzk+gIrcxK26mpekHsAewIWSXgCOBcam1dNyFf65sFbB+u+A8yNie+DwFvtaMwPYaRX7xgGD0hifBzYAvlqw/9iIGBwRe0fEUy3fXNiDp6np3Za7q9LCBYvp36/Pyu1+fXuzcOHiDCOqTf6eK2v54uTvyRWvv8Vbtz3IOoO3AqDH1/Zggz2HMvfID/tgxbIVNL6Z3Bt778nn+eDFRay1ebs6w1W1SjUbZqnqkhdwIHBpRHwqIgZERH+SGtJuwJ3A4ZK6wspEB7AUWL/gHC9L2lpSA3BAQfmGfHhzcDyl/RY4QdJW6fUaJH0/Pe9YYPs0xgEkTZ2rajr8mMIePA0N65b7tkw9Mm06AwduxoAB/enWrRtjx47m7zfdkXVYNcffc+U0rL0mDeuuvXJ9/c8P4f1nXmSD3YfQ6/tfYc53TyPeX7by+K49NoCG5NfiGp/sxZqb9eGDl2rvD4emiLKXalWNzYbjgDNalF2blh8JbAU8IWk5SZvp+cBE4DZJC9P7XscDN5E02U0D1kvP80vgGklLgHuAzYoFEhFPSDoGuCLtih/peXcDFkTEwoLDpwDbtPeBuzxobGzk6GNO5JabL6dLQwMXT7qKmTOfzTqsmuPvuXK6brIRm1/wcwDUpQtLbpjC2/c+zjb3/4mGNbox8PKTAXj3sWeZd8IfWe+z29L7p98gVqyApmDez/9I45vvFLtELlVvSiqfSo1dZR2v6xp9/Y9gufdwr6FZh1AXdpx3Q1tuobRqRN89yv6d88CCe1b7eh2hGmteZmbWgTyTspmZ5U6lehtmycnLzKzOVHMvwnI5eZmZ1Zla6Ovg5GVmVmd8z8vMzHLHNS8zM8udxoqOK58NJy8zszpTzSNnlMvJy8yszri3oZmZ5Y5rXmZmljuueZmZWe645mVmZrnj4aHMzCx33GxoZma5E655mZlZ3nh4KDMzyx0PD2VmZrnjmpeZmeVOY5PveZmZWc64t6GZmeWO73mZmVnu+J6XmZnljmteZmaWO+6wYWZmueNmQzMzyx03G5qZWe54ShQzM8sdP+dlZma5Uws1r4asAzAzs87VFE1lL6VI+oKkZyTNlnR8J4QPuOZlZlZ3KtVhQ1IX4PfA3sB84BFJN0bEzIpcoAjXvMzM6kxElL2UMAyYHRFzImIZcCUwusM/AK55VYUVyxYo6xjaStKEiJiYdRy1zN9xx6vX73h5G37nSJoATCgomljwnfUF5hXsmw98dvUjLM01L2uvCaUPsdXk77jj+TsuISImRsTQgqUqkr2Tl5mZtdcCoH/Bdr+0rMM5eZmZWXs9AmwpaTNJawBfB27sjAv7npe1V1U0HdQ4f8cdz9/xaoiIFZJ+BNwOdAH+EhEzOuPaqoUxrszMrL642dDMzHLHycvMzHLHycvMzHLHHTasJEkjga+SdIltBJ4FLoyI2ZkGViMkfaXY/oi4rrNiqWWSxgADgScj4vas47HV4+RlRUn6b2BT4O70dS7wPHCNpF9HxDVZxlcjRhXZF4CT12qS9AdgW+AfwKmShkXEqRmHZavBvQ2tKElPRsT26XpX4L6IGCGpO3B/RGyXbYRmpUl6CtghIholrUPys7tT1nFZ+7nmZaU0SeoREW8AfUie5SAilkjK3ZiM1U7SF0lqCGs1l0XEKdlFVDOWRUQjQET82z+7+efkZaX8Gnhc0rPAp4EfAEjaBPhXlhcL8xMAAAxBSURBVIHVGkl/AtYBRgIXAgcCD2caVO0YJOmJdF3AFum2gIiIz2QXmrWHmw2tJEk9gM1Jpj54M+t4apWkJyLiMwWv6wG3RsRuWceWd5I+VWx/RLzYWbFYZbjmZSWlTYZvtCyXNCgiZmUQUq16L339t6Q+wOtA7wzjqRmrSk6SdgXGAUd0bkS2upy8bHXcAXwy6yBqyE2SNgJ+CzxG0tPwwmxDqj2ShgDfAL5G0nvWvTlzyM2GVpSk81a1CxgfERt0Zjz1QtKawFoR8VbWsdQCSVuR1LDGAa8BVwE/i4iizYlWvZy8rChJS4GfAh+0svusiOjZySHVLEldgC8CAyhoFYmIs7OKqVZIagLuBw5tfrhe0pyI2DzbyKy93GxopTwCPBUR/2i5Q9IvOz+cmvZ34H3gSaAp41hqzVdI5pqaLOk24EqS1gPLKde8rKi0p+H7EfHvrGOpdc29DLOOo5ZJWhcYTdJ8uAdwCXB9RNyRaWDWZh6Y14qKiDdaJi5JO2YVT427VdI+WQdRyyLi3Yi4PCJGkUxZ/xjwnxmHZe3g5GXt4R5wHeNB4HpJ70l6W9JSSW9nHVQtkLSzpP0KyyJiCbAAOC6bqGx1OHlZe/heQcc4G/gcsE5EbBAR67s3Z8WcAcxspXwGyaMJljNOXtYeJ2cdQI2aR9I5xjeiK2/91h5UTsvcYzaH3NvQSkpHk98PGJQWPS2pa0SsyDCsWjQHuFfSrRQ8muCu8hXRvci+dTotCqsY17ysKEl9SZpWfkoyqnxf4FhgRjqEkVXOXJJ509YA1i9YbPXdJem0wtHklTgFuCfDuKyd3FXeipJ0MTA9Iv6nRflRwE4RMT6TwGpM+oDyJRHxzaxjqUVpF/kLgWHA9LR4B2AacFhEvJNVbNY+Tl5WlKRZETFoFfueiYhPd3ZMtUrSVGCPiFiWdSy1StLmJPOlAcyIiDlZxmPt53teVsp7Rfb5weXKmgM8IOlG4N3mQt/zqpw0WTlh1QAnLytlQ0lfaaVcgLtxV9bz6dKA73WZFeVmQytK0v8W2x8R3+msWOpFOgklvg9jtmpOXmZVQtJ2wKVAj7ToNeCQiJiRXVS1IR2jc5XSCVctR5y8rChJPym23/djKkfSP4BfRMTkdHt34NcRsUumgdUASXNJJvcUyQSqS9L1jYCXImKzDMOzdvA9LyvF9146z7rNiQsgIu5Nu3jbampOTpIuIBlF/pZ0ez9gTJaxWfu45mVFSdo5Ih7JOo56IOl6klHOL02LDiZ5lu6A7KKqLZKejIjtS5VZ9fMIG1bKREnPSTpV0jZZB1PjvgtsAlyXLpukZVY5CyWdKGlAuvwCWJh1UNZ2rnlZSZI+TTIL7UHAcuAK4MqIeCHLuMzaKu24cRLweZJ7YFOAU9xhI3+cvKxNJO1AksjGAosjYkTGIeVe+jjCqv5HjIg4tDPjqQeS1o2Id0sfadXKHTasbJIagE8AvYB1gVeyjahm3NRKWX/gx0CXTo6lpknahWSMw/WAT6Z/jB0eET/MNjJrK9e8rCRJuwHjSHplPQlcCVwXEW9lGlgNSsfeO4GkWesc4CKPdVg5kh4CDgRujIghadlTEbFdtpFZW7nmZUVJmge8SJKwfhkRrm11AEmDgBOBISQz+37f86V1jIiYVzAzCkBjVrFY+zl5WSm7RsSLktYCBkr6BDA7It7POrBaIekaYCfgLJKmwkZgg+ZfsO5MUFHz0qbDkNQNOBp4OuOYrB3cbGhFpbMon0bSZfslklEJ+gP/SzIaxPIMw6sJkl7gww4bza/NVYOIiM07PagaJakncC6wF8l3fAdwlP9AyB8nLytK0jkko2z8OCKWpmUbAGcC70XE0VnGZ9YWkkZExAOlyqz6OXlZUZKeA7aKFj8o6cy/syJiy2wiM2s7SY9FxI6lyqz6+Z6XlRItE1da2CjJf/lYLkj6HLALsEmLwaY3wI8j5JKHh7JSZko6pGWhpIOBWRnEY9Yea5A829WVpBm8eXmbpOu85YybDa0oSX1Jxtl7D3g0LR4KrA0cEBELsoqtVniuqc4j6VMR8WLWcdjqc/KyskjaA9g23ZwZEXdnGU8t8VxTnUfSncDXIuLNdLs7yTid+2YbmbWV73lZUZJ2BnpGxK3APQXl+wGvRMSjq3yzlcVzTXWqns2JCyAilqTPLlrO+J6XlXIGMLOV8pkkI0FY5QxvTlwA6R8MnkW5spokfbJ5Q9KnWPWgyFbFXPOyUtZv7R5BOupGzywCqmELJZ0I/DXd/iaea6rSfgFMlXQfSdPsbsCEbEOy9vA9LytK0uyIGNjWfdZ2nmuqc6R/dA1PNx+MiNeyjMfax8nLipL0J+B14MTm572UDLp3MrBpRPiv1grzXFOVJ2lQRMyS1OrDyBHxWGfHZKvHycuKkrQuyfxHw4DpafEOwDTgsIh4J6vYak3hXFMR4bmmKkjSBRHxPUmTW9kdEbFHpwdlq8XJy8qSzjPV3FV+RkTMyTKeWuS5pszK5w4bVpY0WTlhdTDPNdUxJH2l2P6IuK6zYrHKcPIyqx6ea6rjjEpfP0Hy+EHzM4sjgX+QjCJjOeJmQ7Mq4bmmOp6kO4DxEbEo3e4NXOwRNvLHNS8ryuPudapPR8Q3CwskjQA811Tl9G9OXKmXSYbkspxxzcuK8rh7ncdzTXU8SecDWwJXpEUHAbMj4sjsorL2cM3LivK4ex3Pc011noj4kaQDSB4EB5gYEddnGZO1j5OXlWt4RHyveSMibpX0mywDqiEt55pq5rmmOsZjwNKIuEvSOpLWj4ilWQdlbeNmQyuLpNuB+/nouHuf943uyvFcUx1P0vdIxjLsERFbSNoS+FNE7JlxaNZGHlXeyjUO2AS4nqRb8SZpmVXOhZI2at6Q1D39o8Eq5whgBEmtloh4jqT7vOWMmw2tLGmvwqM97l6H8lxTHe+DiFjW/CC4pK54SpRccs3LyiJpF0kzSR+albSDpD9kHFat8VxTHe8+SScAa0vaG7gG+HvGMVk7+J6XlcXj7nU8SV8AJgIfmWsqItx0WCHpjAiHAfuQfMe3AxeGfxHmjpsNrWwed69jRcRt6ZQdzXNNHeO5pipHUheSQaUHARdkHY+tHjcbWrk+Mu6epJ/hcfcqQtKg9HVHkgfBF6bLJ1c1/5S1XUQ0As8UNs1afrnZ0Mricfc6juea6jySpgBDgIeBlR2PIuLLmQVl7eLkZWWRNCIiHihVZlbNJP1Ha+URcV9nx2Krx8nLyuJx9zqO55rqeJLWAr4PDASeBC6KiBXZRmWrwx02rCiPu9cpPNdUx5sELCcZJWY/YBuS+dIsp5y8rBSPu9fBIuI7sHKuqW1azjWVYWi1ZJuI2B5A0kUk97wsx5y8rKj0XsB9ki72uHsdznNNdZzlzSsRsaLFIx+WQ05eVq4LJX2tefgiSd2BKz0wb0XdnY5lWDjX1F0ZxlNLdpD0droukhE23k7XIyI2yC40aw932LCySHq8eWSNYmW2elrMNTXFc02Ztc41LytXk6RPRsRL4HH3OpDnmjIrg5OXlesXwFRJHxl3L9uQakvhXFPAFkBf4E+A55oya8HNhla2dJSN5nH3HvS4e5UlaTowDHioYPDjJ5t7yZnZhzy2oRXlcfc61QcRsax5w3NNma2amw2tlJ8C3wPOamVfAB53r3JazjX1QzzXlFmr3GxoViU815RZ+Zy8rCiPu9c5Wsw1ZWYluNnQSvG4e50gIholPVP4OIKZrZqTlxXlcfc6VXdghiTPNWVWgpOXlcvj7nW8/8o6ALO8cPKycnncvQ7iuabM2s4dNqxsHnevY0i6io/ONfViRHiuKbMinLysbOl4hls2j7sHdPG4e6uvcBSN9MHkhz1DtVlxHmHDypKOu/c34M9pUV/g/7KLqKZ8ZK6pLAMxywvXvKwsHnev40hq5MPehQLWBv6N55oyWyV32LByfRARy5pnoPW4e5UTEV2yjsEsb9xsaOVqOe7eNXjcPTPLiJsNrSwed8/MqomTl5XkcffMrNq42dBKiohG4BlJHlHDzKqCO2xYuTzunplVDScvK5fH3TOzquHkZUV53D0zq0busGFFedw9M6tGTl5WlMfdM7Nq5N6GVorH3TOzquOalxXlcffMrBo5eZmZWe642dDMzHLHycvMzHLHycvMzHLHycvMzHLHycvMzHLHycvMzHLn/wNoeXdVwBF/hwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true=test.classes,y_pred=rounded_labels,target_names =['COVID-19','Normal','CAP']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRlVdWAxG6FL",
        "outputId": "45e52785-7351-4ee1-98fc-d7f56a82ac93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    COVID-19       0.99      1.00      0.99      1041\n",
            "      Normal       0.99      0.97      0.98       485\n",
            "         CAP       1.00      1.00      1.00       525\n",
            "\n",
            "    accuracy                           0.99      2051\n",
            "   macro avg       0.99      0.99      0.99      2051\n",
            "weighted avg       0.99      0.99      0.99      2051\n",
            "\n"
          ]
        }
      ]
    }
  ]
}